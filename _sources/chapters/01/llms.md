# LLM fundamentals

| Term                | Description                                                                                                 |
|---------------------|-------------------------------------------------------------------------------------------------------------|
| System Prompt       | General instruction for the LLM to follow, used as a prefix to every query.                                |
| User Prompt         | The user input to the model.                                                                                |
| Context Window      | The maximum number of tokens the model can process in a single input sequence.                             |
| Inference           | The process of generating outputs (predictions or responses) from a model given new input data.              |
| Parameters          | The learned weights in a model that are optimized during training to capture patterns in the data.          |
| Hyperparameters     | Configurable settings (like learning rate, batch size, number of layers) that govern the training process.   |
| Fine-tuning         | Adapting a pre-trained model to a specific task or dataset to improve performance.                         |
| Token               | A basic unit of text (word, subword, or character) that the model processes.                                |
| Tokenization        | The process of converting text into tokens, which the model uses as input or output units.                    |
| Embedding           | A numerical representation of text that captures semantic meaning and context.                              |